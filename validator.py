import asyncio
import re
from typing import List, Dict, Tuple, Optional
import logging

import httpx
from bs4 import BeautifulSoup
import urllib.parse

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π —Å—Ç–µ–ª—Å-—á–µ–∫–µ—Ä –ì–ê–†–ê–ù–¢
try:
    from garant_checker import GarantCheckerParallel, enhance_validation_with_garant
    GARANT_AVAILABLE = True
except ImportError:
    GARANT_AVAILABLE = False

EXPIRED_KEYWORDS = [
    "–Ω–µ –¥–µ–π—Å—Ç–≤—É–µ—Ç",
    "—É—Ç—Ä–∞—Ç–∏–ª —Å–∏–ª—É",
    "—É—Ç—Ä–∞—Ç–∏–ª–∞ —Å–∏–ª—É",
    "—É—Ç—Ä–∞—Ç–∏–ª–æ —Å–∏–ª—É",
    "–ø—Ä–∏–∑–Ω–∞–Ω —É—Ç—Ä–∞—Ç–∏–≤—à–∏–º —Å–∏–ª—É",
    "–æ—Ç–º–µ–Ω–µ–Ω",
    "–æ—Ç–º–µ–Ω–µ–Ω–∞",
    "–∑–∞–º–µ–Ω–µ–Ω",
    "–∑–∞–º–µ–Ω–µ–Ω–∞",
]
ACTIVE_KEYWORDS = [
    "–¥–µ–π—Å—Ç–≤—É–µ—Ç",
    "–¥–µ–π—Å—Ç–≤—É—é—â–∞—è —Ä–µ–¥–∞–∫—Ü–∏—è",
    "–∞–∫—Ç—É–∞–ª—å–Ω–æ",
]

SOURCES = {
    # –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ
    "pravo.gov.ru": "https://pravo.gov.ru/search/?query={query}",
    "consultant.ru": "https://www.consultant.ru/search/?q={query}",
    "garant.ru": "https://www.garant.ru/search/?q={query}",
    "rulaws.ru": "https://rulaws.ru/search/?q={query}",
    # —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã
    "docs.cntd.ru": "https://docs.cntd.ru/search/?searchtext={query}",
    "gostrf.com": "https://gostrf.com/search/?q={query}",
    "standartgost.ru": "https://standartgost.ru/search/?q={query}",
    "gov.spb.ru": "https://www.gov.spb.ru/search/?q={query}",
    "gostassistent.ru": "https://gostassistent.ru/search?q={query}",
}

HEADERS = {
    "User-Agent": "Mozilla/5.0 (compatible; DocumentValidator/1.0; +https://example.com)"
}


async def _fetch(client: httpx.AsyncClient, url: str) -> Tuple[str, str]:
    try:
        logger.info(f"Checking source: {url}")
        resp = await client.get(url, timeout=10.0)  # Reduced timeout
        resp.raise_for_status()
        logger.info(f"Successfully checked {url}")
        return url, resp.text.lower()
    except httpx.TimeoutException:
        logger.warning(f"Timeout while checking {url}")
        return url, ""
    except httpx.HTTPStatusError as e:
        logger.warning(f"HTTP error {e.response.status_code} while checking {url}")
        return url, ""
    except Exception as e:
        logger.warning(f"Error checking {url}: {str(e)}")
        return url, ""


async def _second_pass_check(query: str) -> Optional[Tuple[str, str]]:
    """Dedicated check against gostassistent.ru if first pass returned unknown."""
    url = f"https://gostassistent.ru/search?q={query}"
    async with httpx.AsyncClient(headers=HEADERS, follow_redirects=True) as client:
        try:
            resp = await client.get(url, timeout=20)
            resp.raise_for_status()
            return url, resp.text.lower()
        except Exception:
            return None


async def validate_reference(ref_raw: str, max_sources: int | None = None) -> Dict:
    """Validate a reference across multiple sources.

    Returns dict with keys: source_results (dict of url -> html), status, confidence
    """
    tasks = []
    query = urllib.parse.quote_plus(ref_raw)

    # Add connection and rate limiting
    limits = httpx.Limits(max_keepalive_connections=5, max_connections=10)
    async with httpx.AsyncClient(
        headers=HEADERS, 
        follow_redirects=True,
        limits=limits,
        timeout=10.0  # Global timeout
    ) as client:
        logger.info(f"Starting validation for: {ref_raw}")
        for i, (name, tmpl) in enumerate(SOURCES.items()):
            if max_sources and i >= max_sources:
                break
            url = tmpl.format(query=query)
            tasks.append(_fetch(client, url))
        
        # Use timeout for gather to prevent infinite waiting
        try:
            results = await asyncio.wait_for(asyncio.gather(*tasks), timeout=30.0)
        except asyncio.TimeoutError:
            logger.error("Timeout while gathering results from all sources")
            results = [(url, "") for url in SOURCES.values()]

    status_counts = {"expired": 0, "active": 0, "unknown": 0}
    source_status: Dict[str, str] = {}

    for url, html in results:
        if not html:
            source_status[url] = "unknown"
            status_counts["unknown"] += 1
            continue
        html_lc = html.lower()
        expired = any(k in html_lc for k in EXPIRED_KEYWORDS)
        active = any(k in html_lc for k in ACTIVE_KEYWORDS)
        if expired and not active:
            st = "–ø—Ä–æ—Å—Ä–æ—á–µ–Ω–æ"
            status_counts["expired"] += 1
        elif active and not expired:
            st = "–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ"
            status_counts["active"] += 1
        else:
            st = "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
            status_counts["unknown"] += 1
        source_status[url] = st

    total = sum(status_counts.values())
    if total == 0:
        final = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        conf = 0.0
    elif status_counts["expired"] >= status_counts["active"] and status_counts["expired"] > 0:
        final = "–ü—Ä–æ—Å—Ä–æ—á–µ–Ω–æ"
        conf = status_counts["expired"] / total
    elif status_counts["active"] > status_counts["expired"]:
        final = "–î–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ"
        conf = status_counts["active"] / total
    else:
        final = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        conf = 0.0

    # After final calculation, if status Unknown we call second pass
    if final == "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ":
        second = await _second_pass_check(query)
        if second:
            url2, html2 = second
            expired2 = any(k in html2 for k in EXPIRED_KEYWORDS)
            active2 = any(k in html2 for k in ACTIVE_KEYWORDS)
            if expired2 != active2:  # only if we can determine
                final = "–ü—Ä–æ—Å—Ä–æ—á–µ–Ω–æ" if expired2 else "–î–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ"
                conf = 1.0
            source_status[url2] = final.lower()

    return {
        "–∏—Å—Ç–æ—á–Ω–∏–∫_—Å—Ç–∞—Ç—É—Å—ã": source_status,
        "—Å—Ç–∞—Ç—É—Å": final,
        "—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å": round(conf, 2),
    }


async def bulk_validate(refs: List[str]) -> Dict[str, Dict]:
    """Validate multiple references concurrently."""
    tasks = [validate_reference(r) for r in refs]
    results_list = await asyncio.gather(*tasks)
    return {ref: res for ref, res in zip(refs, results_list)}


async def bulk_validate_enhanced(refs: List, use_garant: bool = True, progress_callback=None) -> Dict[str, Dict]:
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ —á–µ—Ä–µ–∑ –ì–ê–†–ê–ù–¢
    
    Args:
        refs: –°–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ Reference –∏–ª–∏ —Å—Ç—Ä–æ–∫
        use_garant: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –ø—Ä–æ–≤–µ—Ä–∫—É —á–µ—Ä–µ–∑ –ì–ê–†–ê–ù–¢
        progress_callback: Callback —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    """
    # –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é
    ref_strings = []
    for ref in refs:
        if hasattr(ref, 'raw'):
            ref_strings.append(ref.raw)
        else:
            ref_strings.append(str(ref))
    
    if progress_callback:
        progress_callback("üîç –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –±–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏...")
    
    validation_results = await bulk_validate(ref_strings)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    unknown_count = sum(
        1 for result in validation_results.values() 
        if result.get("—Å—Ç–∞—Ç—É—Å", "").lower() == "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
    )
    
    if progress_callback:
        progress_callback(f"üìä –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Å—Ç–∞—Ç—É—Å–æ–≤: {unknown_count}")
    
    # –ï—Å–ª–∏ –º–Ω–æ–≥–æ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Å—Ç–∞—Ç—É—Å–æ–≤ –∏ –¥–æ—Å—Ç—É–ø–µ–Ω –ì–ê–†–ê–ù–¢ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
    if use_garant and GARANT_AVAILABLE and unknown_count > 10:
        if progress_callback:
            progress_callback(f"üéØ –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ –ì–ê–†–ê–ù–¢ –¥–ª—è {unknown_count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ–∫–∏ –æ–±—Ä–∞—Ç–Ω–æ –≤ Reference –æ–±—ä–µ–∫—Ç—ã –¥–ª—è –ì–ê–†–ê–ù–¢
        ref_objects = []
        if hasattr(refs[0], 'raw'):  # –ï—Å–ª–∏ —É–∂–µ Reference –æ–±—ä–µ–∫—Ç—ã
            ref_objects = refs
        else:
            # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∏, —Å–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ Reference –æ–±—ä–µ–∫—Ç—ã
            from references_extractor import Reference
            ref_objects = [
                Reference(raw=ref_str, type="–î–æ–∫—É–º–µ–Ω—Ç", number=None, date=None, title=None)
                for ref_str in ref_strings
            ]
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π (5 Chrome –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤)
        validation_results = enhance_validation_with_garant(ref_objects, validation_results)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        final_unknown_count = sum(
            1 for result in validation_results.values() 
            if result.get("—Å—Ç–∞—Ç—É—Å", "").lower() == "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        )
        
        improved_count = unknown_count - final_unknown_count
        if progress_callback:
            progress_callback(f"‚úÖ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ –ì–ê–†–ê–ù–¢ (5 Chrome –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤) —É–ª—É—á—à–∏–ª–∞ —Å—Ç–∞—Ç—É—Å –¥–ª—è {improved_count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        
    elif use_garant and unknown_count > 10 and not GARANT_AVAILABLE:
        if progress_callback:
            progress_callback("‚ö†Ô∏è  –ù—É–∂–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ –ì–ê–†–ê–ù–¢, –Ω–æ –º–æ–¥—É–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        
    return validation_results 